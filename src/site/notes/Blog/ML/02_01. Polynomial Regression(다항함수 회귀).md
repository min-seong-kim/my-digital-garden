---
{"dg-publish":true,"permalink":"/blog/ml/02-01-polynomial-regression/"}
---

이전까지 본 내용들은 간단한 선형 함수 회귀였다. 

$$ h(x) = \theta_0 + \theta+1 x_1 + \theta_2 x_2 $$
여기서 특징들의 개수가 증가하게 될 경우 이를 다항함수로 구성할 수 있다.
$$ h(x) = \theta_0 + \theta_1 x + \theta_2 x^2 + \theta_3 x^3 + ... $$
이는 하나의 feature $x$를 다양한 방식으로 변환한 것이다.
이때 $x = x_1$ , $x^2 = x_2$ 를 의미한다.
각각의 다항함수 항이 서로 다른 feature를 의미하고 다항식의 관계에 있다고 가정한 것.

그럼 왜 이렇게 복잡한 형식으로 나타내는 것인가?

# Taylor series

바로 테일러 급수를 적용하기 위해서이다.

> 미적분학에서 테일러 급수는 도함수들의 한 점에서의 값으로 계산된 항의 무한합으로 해석함수를 나타내는 방법

- f(x)가 굉장히 복잡한 형태일 경우 이를 다항함수의 형태로 근사하는 방식
	- 적어도 x=a라는 지점 근처에서 유사하도록

$$ f(a) + \frac{f'(a)}{1!}(x-a) + \frac{f''(a)}{2!}(x-a)^2 + \frac{f'''(a)}{3!}(x-a)^3 + ... $$ 보통 1,2차까지만 테일러 급수를 얻어서 Gradient Descent같은 방식의 방향성을 얻는다.

테일러 급수를 사용하면 어떤 함수라도 미분이 훨씬 쉬운 형태인 다항함수의 형태로 고쳐 쓸 수 있기에 회귀에서 사용된다.

$$ y(x,w) = w_0, w_1 x+ w_2 x^2 + ... + w_M x^m = \sum^M_{j=0} w_j x^j $$

복잡한 함수 f(x,y)와 training data의 관계를 테일러 급수 전개를 통해 f가 특정 범위에서 근사한다면,
위와 같은 다항함수 식에다 $w_0 \sim w_m$까지의 적당한 값을 대입하면 $f$라는 함수가 정확히 뭔 지는 모르지만 noisy한 데이터 샘플들 근처에 "근사"할 수 있다. 

다항함수의 차수가 너무 낮으면 회귀 성능이 낮아지고 너무 높으면 오버피팅이 될 수 있으므로 주의해야 한다.
